{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yotam-biu/tutorial8/blob/main/data_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81c8617c",
      "metadata": {
        "id": "81c8617c"
      },
      "source": [
        "## Dependency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f87a631",
      "metadata": {
        "id": "2f87a631"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83c67fc4",
      "metadata": {
        "id": "83c67fc4"
      },
      "source": [
        "## Load the data and get a glimpse on it"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d63a0004",
      "metadata": {
        "id": "d63a0004"
      },
      "source": [
        "#### Penguins data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.  \n",
        "Read the CSV file from the following link into a DataFrame:  \n",
        "   [Palmer Penguins CSV](https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/inst/extdata/penguins.csv)  \n",
        "   \n",
        "Use the `pandas` library's `read_csv` function to load the data.  \n",
        "\n",
        "Inspect the first few rows of the DataFrame to understand its structure and content.  \n",
        "\n",
        "**Hint:** Remember to pass the URL directly to the function.\n"
      ],
      "metadata": {
        "id": "hUVauVqUrhsP"
      },
      "id": "hUVauVqUrhsP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8eb98d41",
      "metadata": {
        "id": "8eb98d41"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c6d13c4",
      "metadata": {
        "id": "3c6d13c4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "b8ae1463",
      "metadata": {
        "id": "b8ae1463"
      },
      "source": [
        "## Retrieving data\n",
        "Retrieving data in data science typically refers to the process of accessing and extracting specific subsets of data from a dataset. This operation is crucial for analyzing and working with data effectively. In this context, retrieving data can involve operations such as filtering rows, selecting columns, sorting, grouping, and aggregating data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Filter\n",
        "\n",
        "Filter the DataFrame to include only rows where the value in the `sex` column is \"female\".  \n",
        "\n",
        "Assign the filtered DataFrame to a new variable named `data_female`.  \n",
        "\n",
        "**Hint:** Use the syntax `data[condition]` to filter rows based on a condition.  \n"
      ],
      "metadata": {
        "id": "XpRRt6zQsGn1"
      },
      "id": "XpRRt6zQsGn1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28d8f747",
      "metadata": {
        "id": "28d8f747"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "dda41eda",
      "metadata": {
        "id": "dda41eda"
      },
      "source": [
        "## Cleaning the data\n",
        "\n",
        "Cleaning data is an essential step in the data science process. It involves identifying and handling missing values, handling duplicates, addressing inconsistencies or errors in the data, and transforming the data into a consistent and usable format."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Remove None\n",
        "\n",
        "Use the `dropna()` method of the data-frame object to remove all rows with missing values from the DataFrame.  \n",
        "Before applying the method, check the number of rows in the DataFrame using `len(data)` to understand the size of the data.  \n",
        "Apply `dropna()` and assign the result back to the `data` variable.  \n",
        "After applying the method, check the number of rows again using `len(data)` to confirm how many rows were removed.  \n"
      ],
      "metadata": {
        "id": "A7z0W2v0s14q"
      },
      "id": "A7z0W2v0s14q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7bb30d4",
      "metadata": {
        "id": "c7bb30d4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "59d9cca7",
      "metadata": {
        "id": "59d9cca7"
      },
      "source": [
        "\n",
        "## 4. Remove Duplicate\n",
        "Use the `drop_duplicates()` method of the data-frame object to remove duplicate rows from the DataFrame.  \n",
        "Before applying the method, check the number of rows in the DataFrame using `len(data)` to see the current size of the data.  \n",
        "Then, Apply `drop_duplicates()` and assign the result back to the `data` variable.  \n",
        "After applying the method, check the number of rows again using `len(data)` to see how many duplicate rows were removed.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c67f1cd5",
      "metadata": {
        "id": "c67f1cd5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "c5ededf9",
      "metadata": {
        "id": "c5ededf9"
      },
      "source": [
        "## 5. Filter By Z-Score\n",
        "Calculate the z-scores for the `body_mass_g` column to identify how far each value deviates from the column's mean in terms of standard deviations.  \n",
        "\n",
        "Use the formula for z-score:  \n",
        "$$\n",
        "   z = \\frac{{\\text{{value}} - \\text{{mean}}}}{{\\text{{standard deviation}}}}\n",
        "$$  \n",
        "\n",
        "Create a threshold of 2.5 to determine which values are considered outliers (i.e., values with a z-score greater than 2.5).  \n",
        "\n",
        "Check the `body_mass_g` values of the outliers to understand their magnitudes.\n",
        "\n",
        "\n",
        "Filter the DataFrame to include only the rows where the `body_mass_g` z-score exceeds the threshold.  \n",
        "\n",
        "Again, cheak the number of rows before and after the filter.\n",
        "\n",
        "**Hint:** Use `np.abs()` to ensure all z-scores are positive, and apply a condition to filter rows from the DataFrame.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7283fd2d",
      "metadata": {
        "id": "7283fd2d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9eb10acb",
      "metadata": {
        "id": "9eb10acb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "acb9913b",
      "metadata": {
        "id": "acb9913b"
      },
      "source": [
        "## EDA\n",
        "\n",
        "Exploratory Data Analysis (EDA) is a critical step in the data science process. It involves understanding and analyzing the data to uncover patterns, relationships, and insights. EDA helps in formulating hypotheses, identifying data quality issues, selecting appropriate modeling techniques, and preparing the data for further analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ed39958",
      "metadata": {
        "id": "0ed39958"
      },
      "outputs": [],
      "source": [
        "data['species'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "832ae3f0",
      "metadata": {
        "id": "832ae3f0"
      },
      "outputs": [],
      "source": [
        "data.hist(bins=20);\n",
        "plt.tight_layout();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "abbf5bab",
      "metadata": {
        "id": "abbf5bab"
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "501dc01a",
      "metadata": {
        "id": "501dc01a"
      },
      "source": [
        "group by method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5a113e6",
      "metadata": {
        "id": "b5a113e6"
      },
      "outputs": [],
      "source": [
        "data.groupby('species').mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c62fd35",
      "metadata": {
        "id": "8c62fd35"
      },
      "outputs": [],
      "source": [
        "data.groupby('species').agg(['mean', 'median'])  # passing a list of recognized strings"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6.\n",
        "\n",
        "* Import the necessary libraries: `matplotlib.pyplot` or `seaborn`.  \n",
        "\n",
        "* Assume you have a DataFrame named `data` that contains a column named `species` and another numerical column, `flipper_length_mm`.  \n",
        "\n",
        "* Group the data by the `species` column using the `groupby()` method.  \n",
        "\n",
        "* For each species, create a histogram of the `flipper_length_mm` column. Use a different color for each species and set the `alpha` parameter to make the bars semi-transparent.  \n",
        "\n",
        "* Add appropriate labels (`xlabel`, `ylabel`) and a title to the plot to describe the data.  \n",
        "\n",
        "* Include a legend to identify the species represented by each histogram.  \n",
        "\n",
        "* Display the histogram using `plt.show()`.  \n",
        "\n",
        "**Hint:** Use a loop to iterate through each group returned by `groupby()`. The loop will provide the species name and the data subset for that species.\n"
      ],
      "metadata": {
        "id": "yDbGw6ADwOvw"
      },
      "id": "yDbGw6ADwOvw"
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = data.groupby('species')\n",
        "for species, species_data in grouped:\n",
        "    print(species, len(species_data))"
      ],
      "metadata": {
        "id": "Yqo7wkQ9w1eJ"
      },
      "id": "Yqo7wkQ9w1eJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "714ff5c3",
      "metadata": {
        "id": "714ff5c3"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Group the data by species\n",
        "\n",
        "# Plot a histogram for each species with different colors\n",
        "for species, species_data in grouped:\n",
        "    pass # replace pass with the loop content\n",
        "\n",
        "# Add labels and title to the plot\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "# Display the plot\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31284397",
      "metadata": {
        "id": "31284397"
      },
      "outputs": [],
      "source": [
        "\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_context(\"paper\", font_scale=2)\n",
        "sns.relplot(\n",
        "    data = data,\n",
        "    x = 'bill_length_mm',\n",
        "    y = 'flipper_length_mm',\n",
        "    hue = 'species',\n",
        "    height=8,\n",
        "    hue_order = ['Adelie', 'Gentoo', 'Chinstrap']);"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.\n",
        "\n",
        "* Explore the relationship between different columns in the `data` DataFrame by creating your own scatter plot using `sns.relplot()`.  \n",
        "\n",
        "* Choose different columns for the `x` and `y` axes to visualize a new aspect of the dataset.  \n",
        "\n",
        "* Use the `hue` parameter to color the points by a categorical column, such as `species` or another relevant column.  \n",
        "\n",
        "* Customize the plot by setting attributes like `height` or `hue_order` as needed.  \n",
        "\n",
        "* Experiment with the `style` or `size` parameters in `sns.relplot()` to add more dimensions to your plot.  \n",
        "\n",
        "* Display your plot and ensure it is clear and well-labeled.  \n",
        "\n",
        "**Hint:** Refer to the provided example for guidance on using `sns.relplot()`. Consider exploring combinations of columns like `body_mass_g` and `bill_depth_mm`.\n"
      ],
      "metadata": {
        "id": "1h3Etxk-yBuU"
      },
      "id": "1h3Etxk-yBuU"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Go Over the Following Plots"
      ],
      "metadata": {
        "id": "o1GapHFJyUYZ"
      },
      "id": "o1GapHFJyUYZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41fc4f53",
      "metadata": {
        "id": "41fc4f53"
      },
      "outputs": [],
      "source": [
        "sns.set_context('talk')\n",
        "sns.pairplot(data.drop(columns = ['year']), hue='species');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d054efc6",
      "metadata": {
        "id": "d054efc6"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(data=data, hue = 'species', x='species', y='flipper_length_mm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "675d7a28",
      "metadata": {
        "id": "675d7a28"
      },
      "outputs": [],
      "source": [
        "columns = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']\n",
        "\n",
        "fig, axs = plt.subplots(1, len(columns), figsize=(20,5))\n",
        "\n",
        "for i, col in enumerate(columns):\n",
        "    sns.boxplot(data=data, x='species', y=col, hue='species', ax = axs[i])\n",
        "    axs[i].legend([], [], frameon=False)\n",
        "    axs[i].set_xlabel(None)\n",
        "    axs[i].set_ylabel(None)\n",
        "    axs[i].set_title(col, fontsize = 20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7346622a",
      "metadata": {
        "id": "7346622a"
      },
      "source": [
        "After performing Exploratory Data Analysis (EDA), there are several subsequent stages in the data science process. Here's a brief summary of some common stages that typically follow EDA:\n",
        "\n",
        "* **Feature Engineering**: This stage involves transforming and creating new features from the existing data to improve the performance of machine learning models. Feature engineering can include techniques such as scaling, normalization, one-hot encoding, handling missing values, creating interaction terms, and deriving new features based on domain knowledge.\n",
        "\n",
        "* **Model Selection**: In this stage, various machine learning algorithms or models are evaluated and compared to select the most suitable one for the given problem. The choice of the model depends on the nature of the data, the target variable, the available computational resources, and the desired performance metrics.\n",
        "\n",
        "* **Model Training and Evaluation**: Once the model is selected, it needs to be trained on the labeled data (training set). This involves fitting the model to the data, adjusting its parameters to optimize performance. The trained model is then evaluated using appropriate metrics such as accuracy, precision, recall, F1-score, or area under the ROC curve.\n",
        "\n",
        "* **Hyperparameter Tuning**: Many machine learning algorithms have hyperparameters that control the model's behavior and performance. Hyperparameter tuning involves selecting the optimal combination of hyperparameters to improve the model's performance. Techniques like grid search, random search, or Bayesian optimization can be used for this purpose.\n",
        "\n",
        "* **Model Validation and Testing**: After training and tuning the model, it needs to be validated and tested on unseen data to assess its generalization capabilities. The model is evaluated using a separate validation set or through cross-validation techniques. The final model's performance is assessed on a completely independent test set to estimate its real-world performance.\n",
        "\n",
        "* **Model Deployment**: Once the model is trained, validated, and tested, it can be deployed for real-world use. This involves integrating the model into a production environment, making predictions on new data, and monitoring its performance over time. Deployment may involve the use of frameworks, APIs, or cloud services to enable model serving and inference.\n",
        "\n",
        "* **Monitoring and Maintenance**: After deployment, it's important to monitor the model's performance and behavior in production. Regular maintenance and retraining may be necessary to keep the model up to date and ensure its continued accuracy and reliability.\n",
        "\n",
        "These stages are not necessarily linear and may involve iterations and feedback loops. The exact sequence and scope of these stages may vary depending on the specific problem, data, and requirements of the project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7b48bcc",
      "metadata": {
        "id": "a7b48bcc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}